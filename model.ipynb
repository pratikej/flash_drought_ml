{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Historical Days used as Input!\n",
    "num_days_history = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, start_pt, num_pts):\n",
    "        self.start_pt = start_pt\n",
    "        self.num_pts = num_pts\n",
    "\n",
    "        base = \"data/\"\n",
    "        self.input_folder = base + \"input/\"\n",
    "        self.output_folder = base + \"output/\"\n",
    "        self.input_files = os.listdir(self.input_folder)\n",
    "        self.output_files = os.listdir(self.output_folder)\n",
    "\n",
    "        assert (start_pt + num_pts) < len(self.output_files)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_pts\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = []\n",
    "        for i in range(num_days_history):\n",
    "            input.append(torch.load(self.input_folder + self.input_files[self.start_pt + idx + 67 - i]))\n",
    "        input = torch.cat(input, 0)\n",
    "        output = torch.load(self.output_folder + self.output_files[self.start_pt + idx])\n",
    "        return input, output.squeeze().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "train_dataloader = DataLoader(CustomDataset(0, 4680), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(CustomDataset(4680, 730), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1, 42, 676, 407])\n",
      "Labels batch shape: torch.Size([1, 676, 407])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        convs = []\n",
    "        conv_chs = [6 * num_days_history, 512, 256, 64, 16, 2]\n",
    "        for i in range(len(conv_chs) - 1):\n",
    "            convs.append(nn.Conv2d(conv_chs[i], conv_chs[i + 1], kernel_size=(5,5), padding=\"same\"))\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "        self.act = nn.ReLU()\n",
    "        self.LogSoftmax = nn.LogSoftmax(dim=1)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = self.act(conv(x))\n",
    "        x = self.LogSoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "# train_dataloader = DataLoader(CustomDataset(0, 4680), batch_size=BATCH_SIZE, shuffle=True)\n",
    "# test_dataloader = DataLoader(CustomDataset(4680, 730), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_dataloader = DataLoader(CustomDataset(0, 8), batch_size=BATCH_SIZE)\n",
    "\n",
    "train_steps = len(train_dataloader.dataset) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(42, 512, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (1): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (2): Conv2d(256, 64, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (3): Conv2d(64, 16, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (4): Conv2d(16, 2, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "  )\n",
      "  (act): ReLU()\n",
      "  (LogSoftmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# weight = 5\n",
    "# def weightedBCELoss(output, target):\n",
    "#     loss = (weight * (target * torch.log(output))) + ((1 - target) * torch.log(1 - output))\n",
    "#     return torch.neg(torch.mean(loss))\n",
    "\n",
    "model = Net().to(device)\n",
    "loss_fn = nn.NLLLoss(torch.Tensor([1, 50]).to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:09<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.7089, Accuracy: 98.4601, Recall: 0.0000, Precision: 0.0000\n",
      "Model Value: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:01<00:00,  7.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.6926, Accuracy: 98.5096, Recall: 0.0000, Precision: 0.0000\n",
      "Model Value: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:01<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.6931, Accuracy: 98.5096, Recall: 0.0000, Precision: 0.0000\n",
      "Model Value: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:01<00:00,  7.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.6931, Accuracy: 98.5096, Recall: 0.0000, Precision: 0.0000\n",
      "Model Value: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [01:01<00:00,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.6931, Accuracy: 98.5096, Recall: 0.0000, Precision: 0.0000\n",
      "Model Value: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_model_value = 0\n",
    "\n",
    "n_epochs = 5\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_recall = 0\n",
    "    train_precision = 0\n",
    "    for inputs, labels in tqdm(train_dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        y_pred = model(inputs)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss\n",
    "\n",
    "        # pred = y_pred > 0.5\n",
    "        pred = torch.argmax(y_pred, dim=1)\n",
    "        \n",
    "        train_correct += ((pred == labels).float().sum().item() / labels.numel())\n",
    "        train_recall += ((pred[labels > 0] == labels[labels > 0]).float().sum().item() / labels[labels > 0].numel())\n",
    "        if labels[pred > 0].numel() > 0:\n",
    "            train_precision += ((pred[pred > 0] == labels[pred > 0]).float().sum().item() / labels[pred > 0].numel())\n",
    "    \n",
    "    avg_train_loss = total_train_loss / train_steps\n",
    "    train_correct = train_correct / train_steps\n",
    "    train_recall = train_recall / train_steps\n",
    "    train_precision = train_precision / train_steps\n",
    "    \n",
    "    print(\"Epoch: %d, Loss: %.4f, Accuracy: %.4f, Recall: %.4f, Precision: %.4f\" % (epoch+1, avg_train_loss, 100*train_correct, 100*train_recall, 100*train_precision))\n",
    "\n",
    "    model_value = 0\n",
    "    if (train_recall + train_precision) > 1e-4:\n",
    "        model_value = (train_recall * train_precision) / (train_recall + train_precision)\n",
    "    print(\"Model Value:\", model_value)\n",
    "    if model_value > best_model_value:\n",
    "        print(\"Saving Model!\")\n",
    "        torch.save(model.state_dict(), \"model.pt\")\n",
    "        best_model_value = model_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
